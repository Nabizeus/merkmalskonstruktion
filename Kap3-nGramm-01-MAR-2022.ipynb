{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c26e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a7ec39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade die ersten 10.000 Rezensionen\n",
    "f = open('data/yelp_academic_dataset_review.json')\n",
    "js = []\n",
    "for i in range(10000):\n",
    "    js.append(json.loads(f.readline()))\n",
    "f.close()\n",
    "review_df = pd.DataFrame(js)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "847168ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeuge Merkmaltransformatoren für Unigramme, Bigramme und Trigramme.\n",
    "# Bei der Standardeinstellung werden Wörter mit einem Zeichen ignoriert. Dies ist in\n",
    "# der Praxis hilfreich, da nicht informative Wörter ausgelassen werden. Wir beziehen\n",
    "# sie jedoch zu Illustrationszwecken ausdrücklich in dieses Beispiel mit ein.\n",
    "\n",
    "bow_converter = CountVectorizer(token_pattern = '(?u)\\\\b\\\\w+\\\\b')\n",
    "bigram_converter = CountVectorizer(ngram_range=(2,2),\n",
    "                                  token_pattern = '(?u)\\\\b\\\\w+\\\\b')\n",
    "trigram_converter = CountVectorizer(ngram_range=(3,3),\n",
    "                                  token_pattern = '(?u)\\\\b\\\\w+\\\\b')\n",
    "\n",
    "# Passe die Transformatoren an und prüfe die Größe der Vokabulare\n",
    "\n",
    "bow_converter.fit(review_df['text'])\n",
    "words = bow_converter.get_feature_names()\n",
    "bigram_converter.fit(review_df['text'])\n",
    "bigrams = bigram_converter.get_feature_names()\n",
    "trigram_converter.fit(review_df['text'])\n",
    "trigrams = trigram_converter.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7d82710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26558 314991 734771\n"
     ]
    }
   ],
   "source": [
    "print(len(words),len(bigrams), len(trigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4572438b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '00', '000', '003', '00am', '00p', '00pm', '01', '02', '04']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wirf einen Blick auf die n-Gramme selbst.\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d222da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['結合bar和保齡球 氣氛非常好',\n",
       " '虾 蟹也都不错',\n",
       " '蟹也都不错 鸡的味道一般',\n",
       " '蠻特別的地方 結合bar和保齡球',\n",
       " '还吃过什么忘记了 总体菜色味道都还挺好的',\n",
       " '静岡のさわやかはいつ東京にお店出してくれるのだろう あ',\n",
       " '餐馆依水 景致不错',\n",
       " '马兰头 the',\n",
       " '马兰头拌豆腐 the',\n",
       " '鸡的味道一般 还吃过什么忘记了']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56d64a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 1 stars',\n",
       " '0 25 oysters',\n",
       " '0 30 possible',\n",
       " '0 4 miles',\n",
       " '0 40 oz',\n",
       " '0 46 an',\n",
       " '0 50 for',\n",
       " '0 50 on',\n",
       " '0 75 i',\n",
       " '0 99 or']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4825be31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['生のポテトを使ったフライドポテトは好き嫌いあるかもですが ぼくは大好物 バーガーも',\n",
       " '結合bar和保齡球 氣氛非常好 就算沒有要打',\n",
       " '虾 蟹也都不错 鸡的味道一般',\n",
       " '蟹也都不错 鸡的味道一般 还吃过什么忘记了',\n",
       " '蠻特別的地方 結合bar和保齡球 氣氛非常好',\n",
       " '静岡のさわやかはいつ東京にお店出してくれるのだろう あ どこにも書いてないんですが',\n",
       " '餐馆依水 景致不错 在我看来只要不是特别惊艳或难吃',\n",
       " '马兰头 the dish',\n",
       " '马兰头拌豆腐 the vegetable',\n",
       " '鸡的味道一般 还吃过什么忘记了 总体菜色味道都还挺好的']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "701a0221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemmer\n",
    "\n",
    "\n",
    "import nltk\n",
    "stemmer = nltk.stem.porter.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a35e7224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flower'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('flowers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5ba01b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gone'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('gone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a631b197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zero'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('zeroes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f56dc2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('goes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ea105b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion spaCy\n",
    "import spacy\n",
    "# Lade Sprachmodell\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c572dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir können eine Pandas-Reihe von NLP-Variablen aus spaCy erstellen\n",
    "doc_df = review_df['text'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e1d2388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'DET', 'DT']\n",
      "['food', 'NOUN', 'NN']\n",
      "['is', 'AUX', 'VBZ']\n",
      "['always', 'ADV', 'RB']\n",
      "['great', 'ADJ', 'JJ']\n",
      "['here', 'ADV', 'RB']\n",
      "['.', 'PUNCT', '.']\n",
      "['The', 'DET', 'DT']\n",
      "['service', 'NOUN', 'NN']\n",
      "['from', 'ADP', 'IN']\n",
      "['both', 'CCONJ', 'CC']\n",
      "['the', 'DET', 'DT']\n",
      "['manager', 'NOUN', 'NN']\n",
      "['as', 'ADV', 'RB']\n",
      "['well', 'ADV', 'RB']\n",
      "['as', 'ADP', 'IN']\n",
      "['the', 'DET', 'DT']\n",
      "['staff', 'NOUN', 'NN']\n",
      "['is', 'AUX', 'VBZ']\n",
      "['super', 'ADJ', 'JJ']\n",
      "['.', 'PUNCT', '.']\n",
      "['Only', 'ADV', 'RB']\n",
      "['draw', 'VERB', 'VB']\n",
      "['back', 'ADV', 'RB']\n",
      "['of', 'ADP', 'IN']\n",
      "['this', 'DET', 'DT']\n",
      "['restaurant', 'NOUN', 'NN']\n",
      "['is', 'AUX', 'VBZ']\n",
      "['it', 'PRON', 'PRP']\n",
      "[\"'s\", 'AUX', 'VBZ']\n",
      "['super', 'ADV', 'RB']\n",
      "['loud', 'ADJ', 'JJ']\n",
      "['.', 'PUNCT', '.']\n",
      "['If', 'SCONJ', 'IN']\n",
      "['you', 'PRON', 'PRP']\n",
      "['can', 'AUX', 'MD']\n",
      "[',', 'PUNCT', ',']\n",
      "['snag', 'VERB', 'VB']\n",
      "['a', 'DET', 'DT']\n",
      "['patio', 'NOUN', 'NN']\n",
      "['table', 'NOUN', 'NN']\n",
      "['!', 'PUNCT', '.']\n"
     ]
    }
   ],
   "source": [
    "# spaCy liefert uns fein unterschiedene Wortarten mit (.pos_) und grob\n",
    "# unterschiedene Wortarten mit (.tag_)\n",
    "for doc in doc_df[4]:\n",
    "    print([doc.text, doc.pos_, doc.tag_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d55e3d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The food, The service, both the manager, the staff, this restaurant, it, you, a patio table]\n"
     ]
    }
   ],
   "source": [
    "# spaCy nimmt für uns auch eine einfache Substantivprüfung vor.\n",
    "print([chunk for chunk in doc_df[4].noun_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fd19649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /Users/nabizrahpoe/repos/pycedro/pycedro_virt/lib/python3.9/site-packages (from textblob) (3.6.2)\n",
      "Requirement already satisfied: joblib in /Users/nabizrahpoe/repos/pycedro/pycedro_virt/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.0.1)\n",
      "Requirement already satisfied: click in /Users/nabizrahpoe/repos/pycedro/pycedro_virt/lib/python3.9/site-packages (from nltk>=3.1->textblob) (8.0.1)\n",
      "Requirement already satisfied: regex in /Users/nabizrahpoe/repos/pycedro/pycedro_virt/lib/python3.9/site-packages (from nltk>=3.1->textblob) (2021.7.6)\n",
      "Requirement already satisfied: tqdm in /Users/nabizrahpoe/repos/pycedro/pycedro_virt/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.61.2)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d81b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir können dieselben MErkmalstransformationen mit Textblob machen\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e3e99b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Der voreingestellte Tagger in TextBlob verwendet den PatternTagger, was für unser Beispiel in Ordnung ist. Man\n",
    "# kann auch den NLTK-TAgger auswählen, der für unvollständige Sätze besser funktioniert.\n",
    "blob_df = review_df['text'].apply(TextBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a68fa8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('food', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('always', 'RB'),\n",
       " ('great', 'JJ'),\n",
       " ('here', 'RB'),\n",
       " ('The', 'DT'),\n",
       " ('service', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('both', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('manager', 'NN'),\n",
       " ('as', 'RB'),\n",
       " ('well', 'RB'),\n",
       " ('as', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('staff', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('super', 'JJ'),\n",
       " ('Only', 'RB'),\n",
       " ('draw', 'VBZ'),\n",
       " ('back', 'RB'),\n",
       " ('of', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('restaurant', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('super', 'JJ'),\n",
       " ('loud', 'NN'),\n",
       " ('If', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('snag', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('patio', 'NN'),\n",
       " ('table', 'NN')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_df[4].tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "446a1d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/nabizrahpoe/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nabizrahpoe/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nabizrahpoe/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/nabizrahpoe/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     /Users/nabizrahpoe/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/nabizrahpoe/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "!python3 -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "563f6815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['patio table']\n"
     ]
    }
   ],
   "source": [
    "print([np for np in blob_df[4].noun_phrases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520787ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
